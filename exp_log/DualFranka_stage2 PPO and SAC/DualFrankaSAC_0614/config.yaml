task:
  name: DualFranka
  physics_engine: ${..physics_engine}
  rl_device: ${..rl_device}
  env:
    numEnvs: ${resolve_default:10,${...num_envs}}
    numAgents: 1
    envSpacing: 2
    episodeLength: 1000
    enableDebugVis: false
    ResetFromReplay: true
    clipObservations: 5.0
    clipActions: 1.0
    startPositionNoise: 0.0
    startRotationNoise: 0.0
    aggregateMode: 3
    actionScale: 7.5
    dofVelocityScale: 0.1
    distRewardScale: 2.0
    rotRewardScale: 0.5
    aroundHandleRewardScale: 0.25
    liftRewardScale: 0.1
    fingerDistRewardScale: 5.0
    actionPenaltyScale: 0.01
    asset:
      assetRoot: ../../assets
      franka_asset_file: urdf/franka_description/robots/franka_panda.urdf
      cup_asset_file: urdf/cup/urdf/cup.urdf
      stick_asset_file: urdf/stick/urdf/stick.urdf
    enableCameraSensors: false
  sim:
    dt: 0.0166
    substeps: 1
    up_axis: 'y'
    use_gpu_pipeline: ${eq:${...pipeline},"gpu"}
    gravity:
    - 0.0
    - -9.81
    - 0.0
    physx:
      num_threads: ${....num_threads}
      solver_type: ${....solver_type}
      use_gpu: ${contains:"cuda",${....sim_device}}
      num_position_iterations: 12
      num_velocity_iterations: 1
      contact_offset: 0.005
      rest_offset: 0.0
      bounce_threshold_velocity: 0.2
      max_depenetration_velocity: 1000.0
      default_buffer_size_multiplier: 5.0
      max_gpu_contact_pairs: 1048576
      num_subscenes: ${....num_subscenes}
      contact_collection: 1
  task:
    randomize: false
train:
  params:
    seed: ${...seed}
    algo:
      name: sac
    model:
      name: soft_actor_critic
    network:
      name: soft_actor_critic
      separate: true
      space:
        continuous:
          fixed_sigma: false
      mlp:
        units:
        - 256
        - 128
        - 64
        activation: elu
        d2rl: false
        initializer:
          name: default
      log_std_bounds:
      - -5
      - 2
    config:
      name: ${resolve_default:DualFrankaSAC_0614,${....experiment}}
      full_experiment_name: ${.name}
      load_checkpoint: ${if:${....checkpoint},True,False}
      num_actors: ${....task.env.numEnvs}
      env_name: rlgpu
      device: ${....rl_device}
      weight_decay: null
      is_train: ${if:${....test},False,True}
      save_best_after: 40
      print_stats: true
      max_epochs: ${resolve_default:3000,${....max_iterations}}
      reward_shaper:
        scale_value: 1.0
      games_to_track: 100
      actor_update_frequency: 1
      critic_target_update_frequency: 2
      num_seed_steps: 20
      gamma: 0.99
      critic_tau: 0.005
      batch_size: 1024
      init_alpha: 1
      learnable_temperature: true
      replay_buffer_size: 100000
      replay_buffer_path: ${....dataset}
      num_steps_per_episode: 1000
      normalize_input: true
      max_env_steps: 1000
      actor_lr: 3.0e-05
      critic_lr: 0.0003
      alpha_lr: 0.0003
      target_entropy_coef: 0.5
      score_to_win: 40000
      sigma: 0.9
      min_q_weight: 1.0
      min_q_version: 3
      with_lagrange: true
      lagrange_thresh: 5.0
      num_random: 10
task_name: ${task.name}
experiment: ''
num_envs: ''
seed: 42
torch_deterministic: false
max_iterations: ''
physics_engine: physx
pipeline: gpu
sim_device: cuda:1
rl_device: cuda:1
graphics_device_id: 1
num_threads: 4
solver_type: 1
num_subscenes: 4
test: true
checkpoint: /home/ubuntu/isaacgym/IsaacGym_Preview_3_Package/isaacgym/python/IsaacGymEnvs/isaacgymenvs/runs/DualFrankaPPO_0614/nn/DualFrankaPPO_0614.pth
multi_gpu: false
headless: false
dataset: ''
save_hdf5_when_play: false
save_hdf5_folder: test_save/hdf5
